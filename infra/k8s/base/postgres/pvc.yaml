# =============================================================================
# PVC.YAML - PERSISTENT VOLUME CLAIM FOR POSTGRESQL (30GB)
# =============================================================================
# A PersistentVolumeClaim (PVC) is a request for storage by a user/pod.
# It's like a "storage voucher" that Kubernetes fulfills with a PersistentVolume.
#
# Why Persistent Storage for PostgreSQL?
# --------------------------------------
# Without persistent storage, database data is lost when the pod restarts!
# PVCs ensure data survives:
#   - Pod restarts
#   - Pod rescheduling to different nodes
#   - Deployments/rollbacks
#   - Node failures (with proper storage class)
#
# Storage Classes:
# ----------------
# Different clusters have different storage classes:
#   - minikube: "standard" (hostPath)
#   - kind: "standard" (hostPath)
#   - Docker Desktop: "hostpath"
#   - AWS EKS: "gp2", "gp3", "io1"
#   - GCP GKE: "standard", "ssd"
#   - Azure AKS: "default", "managed-premium"
#   - Local cluster: May need to create PV manually
#
# Access Modes:
# -------------
#   - ReadWriteOnce (RWO): Single node read/write (most common for databases)
#   - ReadOnlyMany (ROX): Multiple nodes read-only
#   - ReadWriteMany (RWX): Multiple nodes read/write (requires special storage)
#
# Commands:
#   kubectl apply -f pvc.yaml -n casino
#   kubectl get pvc -n casino
#   kubectl describe pvc postgres-pvc -n casino
# =============================================================================

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
  namespace: casino
  labels:
    app.kubernetes.io/name: postgres
    app.kubernetes.io/component: database
    app.kubernetes.io/part-of: casino-capstone
  annotations:
    description: "30GB persistent storage for PostgreSQL database"
spec:
  # Access mode - ReadWriteOnce means only one node can mount this volume
  # This is appropriate for databases which should only run on one node
  accessModes:
    - ReadWriteOnce
  
  # Storage request - 30GB as specified in requirements
  resources:
    requests:
      storage: 30Gi
  
  # Storage class - adjust based on your cluster
  # Comment out to use cluster default, or specify explicitly
  # storageClassName: standard        # minikube, kind
  # storageClassName: gp2             # AWS EKS
  # storageClassName: standard-rwo    # GKE
  # storageClassName: managed-premium # Azure AKS
  
  # Volume mode - Filesystem is default and what PostgreSQL needs
  volumeMode: Filesystem

---
# =============================================================================
# PERSISTENT VOLUME (Optional - for local clusters without dynamic provisioning)
# =============================================================================
# If your cluster doesn't have a storage provisioner (dynamic provisioning),
# you need to create a PersistentVolume manually.
#
# This is common for:
#   - Bare metal clusters
#   - Local development clusters without CSI drivers
#   - On-premises Kubernetes
#
# For cloud providers (EKS, GKE, AKS), you usually don't need this -
# they have dynamic provisioning that creates PVs automatically.
#
# Uncomment the section below if you need to manually create the PV.
# =============================================================================

# apiVersion: v1
# kind: PersistentVolume
# metadata:
#   name: postgres-pv
#   labels:
#     app.kubernetes.io/name: postgres
#     app.kubernetes.io/component: database
#     app.kubernetes.io/part-of: casino-capstone
#     type: local
# spec:
#   # Storage capacity - must be >= PVC request
#   capacity:
#     storage: 30Gi
#   
#   # Access mode - must match PVC
#   accessModes:
#     - ReadWriteOnce
#   
#   # Reclaim policy:
#   #   - Retain: Keep data when PVC is deleted (manual cleanup required)
#   #   - Delete: Delete data when PVC is deleted
#   #   - Recycle: Deprecated, don't use
#   persistentVolumeReclaimPolicy: Retain
#   
#   # Storage class - must match PVC or be empty for default
#   storageClassName: standard
#   
#   # Host path for local storage (NOT for production!)
#   # For production, use proper storage backends (NFS, iSCSI, cloud storage)
#   hostPath:
#     path: /data/postgres
#     type: DirectoryOrCreate
#   
#   # Node affinity - bind to specific node (for hostPath)
#   nodeAffinity:
#     required:
#       nodeSelectorTerms:
#         - matchExpressions:
#             - key: kubernetes.io/hostname
#               operator: In
#               values:
#                 - your-node-name  # Replace with actual node name

---
# =============================================================================
# STORAGE NOTES FOR DIFFERENT ENVIRONMENTS
# =============================================================================
#
# LOCAL DEVELOPMENT (minikube):
# ----------------------------
# minikube has a built-in storage provisioner. Just use:
#   storageClassName: standard
#
# To enable storage addon:
#   minikube addons enable storage-provisioner
#   minikube addons enable default-storageclass
#
#
# LOCAL DEVELOPMENT (kind):
# -------------------------
# kind also has a default storage class. The PVC should work as-is.
#
#
# LOCAL DEVELOPMENT (Docker Desktop):
# -----------------------------------
# Docker Desktop Kubernetes uses:
#   storageClassName: hostpath
#
#
# AWS EKS:
# --------
# EKS uses EBS volumes. Default class is 'gp2'.
# For better performance:
#   storageClassName: gp3
#
# Install EBS CSI driver:
#   eksctl create addon --name aws-ebs-csi-driver --cluster your-cluster
#
#
# GCP GKE:
# --------
# GKE uses Persistent Disks. Options:
#   storageClassName: standard     # HDD
#   storageClassName: ssd          # SSD
#   storageClassName: standard-rwo # Regional HDD
#
#
# AZURE AKS:
# ----------
# AKS uses Azure Disks. Options:
#   storageClassName: default          # Standard HDD
#   storageClassName: managed-premium  # Premium SSD
#
#
# BACKUP CONSIDERATIONS:
# ----------------------
# For production databases, always have a backup strategy:
#   1. Volume snapshots (cloud provider specific)
#   2. pg_dump CronJob to backup to S3/GCS
#   3. Velero for cluster-wide backups
#   4. PostgreSQL streaming replication
# =============================================================================